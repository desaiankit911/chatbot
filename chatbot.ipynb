{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chatbot.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKFEkq35wS-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as f\n",
        "import csv\n",
        "import random\n",
        "import re\n",
        "import os\n",
        "import unicodedata\n",
        "import codecs\n",
        "import itertools"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUA9HGkvSPvd",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1E_N2bNh9NM5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CUDA = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if CUDA else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocZR9wRiBKUn",
        "colab_type": "code",
        "outputId": "67d54de6-ccb6-41c9-a257-0132dc95d9cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBZsXzT5F_Eb",
        "colab_type": "code",
        "outputId": "f60bd608-0a51-40c8-e573-3b94a2a10e45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "file = \"data.zip\"\n",
        "\n",
        "with ZipFile(file,'r') as zip:\n",
        "    zip.extractall()\n",
        "    print('done')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGiZVfL-HDdF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#line file  \n",
        "lines_filepath = os.path.join(\"cornell movie-dialogs corpus\",\"movie_lines.txt\")\n",
        "#conversation file\n",
        "con_filepath = os.path.join(\"cornell movie-dialogs corpus\",\"movie_conversations.txt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pK_99Hw6HdXn",
        "colab_type": "code",
        "outputId": "4f97bde5-6a2c-433a-a31c-3de0154aab0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "#visualize some lines\n",
        "#as its already 'utf-8' coded so this codec can't decode byte 0xad thats why insted read i.e 'r' use 'rb'\n",
        "with open(lines_filepath,'rb') as file:\n",
        "    lines =file.readlines()\n",
        "for line in lines[:8]:\n",
        "    print(line.strip())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!'\n",
            "b'L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!'\n",
            "b'L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.'\n",
            "b'L984 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ She okay?'\n",
            "b\"L925 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Let's go.\"\n",
            "b'L924 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ Wow'\n",
            "b\"L872 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Okay -- you're gonna need to learn how to lie.\"\n",
            "b'L871 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ No'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asJG4CSyHfb3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#split each line of the file into a dictionary of feilds (lineId,characterId,movieId,character,text)\n",
        "\n",
        "line_fields = [\"lineId\",\"characterId\",\"movieId\",\"character\",\"text\"]\n",
        "lines ={}\n",
        "#encode in ASCII\n",
        "with open(lines_filepath,'r',encoding='iso-8859-1') as f:\n",
        "    for line in f:\n",
        "        values = line.split(' +++$+++ ')\n",
        "        #extract fields\n",
        "        lineObj = {}\n",
        "        for i, field in enumerate(line_fields):\n",
        "            #lineObj is dictionary which contaion all lines_fields as key and values\n",
        "            lineObj[field] = values[i]\n",
        "        #key for lines dictionary is lineIdand value is lineObj\n",
        "        lines[lineObj[\"lineId\"]] = lineObj"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2Rb7DckYR-f",
        "colab_type": "code",
        "outputId": "cfa18b6a-7a0d-41cd-b839-2feed7e8814c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "#1st element of lines dictionary\n",
        "l = lines\n",
        "list(l.items())[0]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('L1045',\n",
              " {'character': 'BIANCA',\n",
              "  'characterId': 'u0',\n",
              "  'lineId': 'L1045',\n",
              "  'movieId': 'm0',\n",
              "  'text': 'They do not!\\n'})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cuz9DvdDmfqo",
        "colab_type": "code",
        "outputId": "d48bc39f-9147-422e-d293-585c291c4bb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "lines['L194']"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'character': 'BIANCA',\n",
              " 'characterId': 'u0',\n",
              " 'lineId': 'L194',\n",
              " 'movieId': 'm0',\n",
              " 'text': 'Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\\n'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tfLfPtVYVjc",
        "colab_type": "code",
        "outputId": "3e3e927f-a242-4784-ed54-56bb41afdd2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "#visualize some conversation file\n",
        "with open(con_filepath,'r') as file:\n",
        "    convs =file.readlines()\n",
        "for line in convs[:8]:\n",
        "    print(line.strip())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L194', 'L195', 'L196', 'L197']\n",
            "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L198', 'L199']\n",
            "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L200', 'L201', 'L202', 'L203']\n",
            "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L204', 'L205', 'L206']\n",
            "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L207', 'L208']\n",
            "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L271', 'L272', 'L273', 'L274', 'L275']\n",
            "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L276', 'L277']\n",
            "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L280', 'L281']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VuVa3EsYZ3k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#split each onversation of the file into a dictionary of feilds (\"character1Id\",\"character2Id\",\"movieId\",\"utteranceIds\")\n",
        "\n",
        "conv_fields = [\"character1Id\",\"character2Id\",\"movieId\",\"utteranceIds\"]\n",
        "conversations =[]\n",
        "with open(con_filepath,'r',encoding='iso-8859-1') as f:\n",
        "    for line in f:\n",
        "        values = line.split(' +++$+++ ')\n",
        "        convObj = {}\n",
        "        for i, field in enumerate(conv_fields):\n",
        "            convObj[field] = values[i]\n",
        "        lineIds = eval(convObj[\"utteranceIds\"])\n",
        "        convObj[\"lines\"] = []\n",
        "        for lineId in lineIds:\n",
        "            convObj[\"lines\"].append(lines[lineId])\n",
        "        conversations.append(convObj)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hqf4u8BoYceR",
        "colab_type": "code",
        "outputId": "edc49c9d-15da-48b2-997a-efe1cc3ac971",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "conversations[0]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'character1Id': 'u0',\n",
              " 'character2Id': 'u2',\n",
              " 'lines': [{'character': 'BIANCA',\n",
              "   'characterId': 'u0',\n",
              "   'lineId': 'L194',\n",
              "   'movieId': 'm0',\n",
              "   'text': 'Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\\n'},\n",
              "  {'character': 'CAMERON',\n",
              "   'characterId': 'u2',\n",
              "   'lineId': 'L195',\n",
              "   'movieId': 'm0',\n",
              "   'text': \"Well, I thought we'd start with pronunciation, if that's okay with you.\\n\"},\n",
              "  {'character': 'BIANCA',\n",
              "   'characterId': 'u0',\n",
              "   'lineId': 'L196',\n",
              "   'movieId': 'm0',\n",
              "   'text': 'Not the hacking and gagging and spitting part.  Please.\\n'},\n",
              "  {'character': 'CAMERON',\n",
              "   'characterId': 'u2',\n",
              "   'lineId': 'L197',\n",
              "   'movieId': 'm0',\n",
              "   'text': \"Okay... then how 'bout we try out some French cuisine.  Saturday?  Night?\\n\"}],\n",
              " 'movieId': 'm0',\n",
              " 'utteranceIds': \"['L194', 'L195', 'L196', 'L197']\\n\"}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvL3PBXnk8Dm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#making question and amswer pair of each conversation  \n",
        "qa_pairs =[]\n",
        "#iterate through the lines inside conversations list\n",
        "for conversation in conversations:\n",
        "  for i in range(len(conversation['lines']) - 1):\n",
        "    inputLine = conversation['lines'][i]['text'].strip()\n",
        "    targetLine = conversation['lines'][i+1]['text'].strip()\n",
        "    #if either inputLine or targetLine is absent than ignore\n",
        "    if inputLine and targetLine:\n",
        "      qa_pairs.append([inputLine,targetLine])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyPvRRtho0Yn",
        "colab_type": "code",
        "outputId": "3d4547dd-09ba-41c4-c083-0b900ec321d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "print(qa_pairs[0])\n",
        "# total number of conversations\n",
        "print('length of coversations = {}'.format(len(qa_pairs)))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.', \"Well, I thought we'd start with pronunciation, if that's okay with you.\"]\n",
            "length of coversations = 221282\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amtEZsASEO4s",
        "colab_type": "code",
        "outputId": "7da75fd9-fe7c-4dad-fdd5-5c69e61d100b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#creae new file contain each line with questions and ansers which is seprated by tab\n",
        "\n",
        "datafile = os.path.join(\"cornell movie-dialogs corpus\",\"formatted_movie_lines.txt\")\n",
        "delimiter = '\\t' #tab\n",
        "#unescape or decode the delimiter\n",
        "delimiter = str(codecs.decode(delimiter,'unicode_escape'))\n",
        "\n",
        "#now write into newly created file\n",
        "print('start writing into the file...')\n",
        "\n",
        "#open newly created file and start writing each line with questions and answers which are seprated by tab\n",
        "with open (datafile, 'w', encoding='utf-8') as outputfile:\n",
        "  writer  = csv.writer(outputfile, delimiter=delimiter)\n",
        "  for pair in qa_pairs:\n",
        "    writer.writerow(pair)\n",
        "print('\\ndone writing')\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "start writing into the file...\n",
            "\n",
            "done writing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQNBiePhIGcS",
        "colab_type": "code",
        "outputId": "563d3c66-beca-4696-c7e3-ef6ad16b4f8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "#visualize some lines inside 'formatted_movie_lines.txt' file\n",
        "\n",
        "datafile = os.path.join(\"cornell movie-dialogs corpus\",\"formatted_movie_lines.txt\")\n",
        "\n",
        "with open(datafile,'rb') as file:\n",
        "  lines = file.readlines()\n",
        "#1st 8 lines each line contain question and answer which are seprated by '\\t'\n",
        "# and each question answer pair seprated by '\\r\\n'\n",
        "for line in lines[:8]:\n",
        "  print(line)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b\"Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\\tWell, I thought we'd start with pronunciation, if that's okay with you.\\r\\n\"\n",
            "b\"Well, I thought we'd start with pronunciation, if that's okay with you.\\tNot the hacking and gagging and spitting part.  Please.\\r\\n\"\n",
            "b\"Not the hacking and gagging and spitting part.  Please.\\tOkay... then how 'bout we try out some French cuisine.  Saturday?  Night?\\r\\n\"\n",
            "b\"You're asking me out.  That's so cute. What's your name again?\\tForget it.\\r\\n\"\n",
            "b\"No, no, it's my fault -- we didn't have a proper introduction ---\\tCameron.\\r\\n\"\n",
            "b\"Cameron.\\tThe thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\\r\\n\"\n",
            "b\"The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\\tSeems like she could get a date easy enough...\\r\\n\"\n",
            "b'Why?\\tUnsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.\\r\\n'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_J8-LcQZeiz",
        "colab_type": "text"
      },
      "source": [
        "# processing the words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zjw8M9Y9Z0pa",
        "colab_type": "text"
      },
      "source": [
        "eah line contain                                     \n",
        "\n",
        "*pad token : if any sentence is shorter than pad it with zero to make all sentence same in length                                    \n",
        "*start of sentence token(SOS token) : indicate the start of sentence                  \n",
        "*End of sentence token(EOS token) : indicate the end of sentence \n",
        "\n",
        "\n",
        "\n",
        "NOTE :\n",
        "addword() method is called 2 times                              \n",
        ">>> *1st time : for counting the number of occurence in sentence using addSentence() method                                                           \n",
        ">>> *2nd time : for deciding which words are importent and should be keept in dictionary and which are not importent should be removed from dictionary (depending upon number of occurence of that word if less than min_count which is nothing but thershokd than remove else keep).      this call in trim() method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tw6WjQC3aYSw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PAD_token = 0\n",
        "SOS_token = 1\n",
        "EOS_token = 2\n",
        "\n",
        "class vocabulary:\n",
        "  def __init__(self,name):\n",
        "    self.name = name\n",
        "    self.word2index = {} #contain word as key and index as value e.g {'hi':0,'he':1,'maybe':2}\n",
        "    self.word2count = {} #contain word as key and freq i.e number of occurence as value\n",
        "    #index2word is opposite of word2index which contain index as key and word as value\n",
        "    self.index2word = {PAD_token : 'PAD', 'SOS_token':'SOS', 'EOS_token':'EOS'}\n",
        "    #count number of words in conversation (it will start with 3 because we already have 'PAD' = 0,'SOS' =1 & 'EOS'=2)\n",
        "    self.num_words = 3\n",
        "\n",
        "  def addSentence(self, sentence):\n",
        "    \"\"\"\n",
        "    sentence.split() convert sentence into list of words\n",
        "    e.g, inut :'hi i am ankit' ; output:['hi','i','am','ankit']\n",
        "    \"\"\"\n",
        "    for word in sentence.split():\n",
        "      self.addword(word)\n",
        "  \n",
        "  def addword(self,word):\n",
        "    #check if word is present in the word2index dictionary or not\n",
        "    if word not in self.word2index:\n",
        "      self.word2index[word] = self.num_words #new word start with value as 3beacuse already PAD,SOS,EOS is present\n",
        "      self.word2count[word] = 1 #start counting word occurence\n",
        "      self.index2word[self.num_words] = word #start key with 3 and value as new word\n",
        "      self.num_words += 1 #increse the num_words for new word in sentence\n",
        "    else:\n",
        "      self.word2count[word] += 1 #count the number of occurence\n",
        "      \n",
        "  def trim(self,min_count):\n",
        "    keep_words = []\n",
        "    for k,v in self.word2count.items():\n",
        "      if v >= min_count:\n",
        "        keep_words.append(k)\n",
        "    print('keep words {} / {} = {:.4f}'.format(len(keep_words),len(self.word2index),len(keep_words)/len(self.word2index)))\n",
        "    #reinitialize dictionaries for storing only required words and remove wich are lesser than thershold\n",
        "    self.word2index = {}\n",
        "    self.word2count = {}\n",
        "    self.index2word = {PAD_token : 'PAD', 'SOS_token':'SOS', 'EOS_token':'EOS'}\n",
        "    self.num_words = 3\n",
        "\n",
        "    for word in keep_words:\n",
        "      self.addword(word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvFfhWXwU8FI",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZmRbR2CtnuQ",
        "colab_type": "text"
      },
      "source": [
        "#Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6T9EYaYlWnr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#turn a unicode string into plain ASCII \n",
        "def unicodeToAscii(string):\n",
        "  \"\"\"\n",
        "  'NFD': normal form decompose , 'Mn' : non marking\n",
        "  in unicodedata.normalize() method we pass two arguments one is NFD and string \n",
        "  if it is 'Mn' than ignore, this method output as tuple and at the end we combine all element in tupe by join methode\n",
        "  \"\"\"\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD',string) if unicodedata.category(c) != 'Mn')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdg4SXFEvKnN",
        "colab_type": "code",
        "outputId": "5fbaf4d8-ff42-41bb-a77e-bf3ec7cf0c17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#example of above method (it convert complex text into plain text by removing all special characctor)\n",
        "unicodeToAscii('Jaimerais,bière,Où,es-tu ....')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Jaimerais,biere,Ou,es-tu ....'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6l3Qac53jRl",
        "colab_type": "text"
      },
      "source": [
        "Now let's conert all characters in string into lowercase, multiple whites paces into single white space,...etc \n",
        "and also remove non-letter characters(i.e either number or sppecial characters)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jb5-H2yf3nrb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalization(string):\n",
        "  #convert string into lower case charactors and remove left and right white spaces\n",
        "  s = unicodeToAscii(string.lower().strip())\n",
        "  #replace '.' with ' .', '!' with ' !', '?' with ' ?' (i.e white space + chracter)\n",
        "  # r is use to not consider ' \\1' as character(r is to escape backspace)\n",
        "  # \\1 meanse 1st bracketed group\n",
        "  s = re.sub(r\"([.!?])\",r\" \\1\",s)\n",
        "  # remove any character which is not sequesnce of lower letters or either any of . ! ? this 3 special charecters.\n",
        "  # + means one or more (e.g input : aaa12a ; output : aaa a)\n",
        "  s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "  # if mutiple white spaces than replce by single space (i.e input :'    '; output:' ')\n",
        "  s = re.sub(r\"\\s+\",r\" \",s).strip()\n",
        "  return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGgk5vBd6vTJ",
        "colab_type": "code",
        "outputId": "8514ebfe-7d42-4d42-a29c-15d688f5463a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#test above function \n",
        "normalization(\"aa123aBc!s's    dd?\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'aa abc !s s dd ?'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCe4yYwFF0qo",
        "colab_type": "text"
      },
      "source": [
        "#processing the text inside \"formatted_mvie_lines.txt\" file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1xuhvVE67pn",
        "colab_type": "code",
        "outputId": "1ad6a325-e73c-4375-8b54-014ea08d50cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "datafile = os.path.join(\"cornell movie-dialogs corpus\",\"formatted_movie_lines.txt\")\n",
        "#read file and split each line (i.e \\n)\n",
        "print(\"reading file......\")\n",
        "lines = open(datafile, encoding = 'utf-8').read().strip().split('\\n')\n",
        "# split each line into pairs and normalize them( after spliting each line by '\\t' we get one list for each line which contain 2 elements question and answer)\n",
        "pairs = [[normalization(s) for s in pair.split('\\t')] for pair in lines]\n",
        "print('done reading!')\n",
        "\n",
        "voc = vocabulary('cornell movie-dialogs corpus')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reading file......\n",
            "done reading!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVovjvYQHQqI",
        "colab_type": "code",
        "outputId": "0a96690b-231a-4778-b59d-837d7d3701da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "#above function results\n",
        "print(\"1. single line of conversation in file is as below : \")\n",
        "print(lines[0])  \n",
        "print(\"\\n 2. after splitinig by '\\t' :\")\n",
        "print(lines[0].split('\\t'))\n",
        "print(\"\\n 3. after normalization of both the elements in list using we created 'normalization' method:\")\n",
        "print(pairs[0])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1. single line of conversation in file is as below : \n",
            "Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\tWell, I thought we'd start with pronunciation, if that's okay with you.\n",
            "\n",
            " 2. after splitinig by '\t' :\n",
            "['Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.', \"Well, I thought we'd start with pronunciation, if that's okay with you.\"]\n",
            "\n",
            " 3. after normalization of both the elements in list using we created 'normalization' method:\n",
            "['can we make this quick ? roxanne korrine and andrew barrett are having an incredibly horrendous public break up on the quad . again .', 'well i thought we d start with pronunciation if that s okay with you .']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZ-p4AzKJO1y",
        "colab_type": "text"
      },
      "source": [
        "#filtering the text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_KD6NIII41a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#if number of words in either question or answer is gretter than length of 9 than remove\n",
        "max_len =10\n",
        "\n",
        "def filterPair(p):\n",
        "  #pair[0] is 1st element and pair[1] is 2nd element is each list inside pairs list(pairs is list contain multile lists)\n",
        "  return [pair for pair in pairs if len(pair[0].split()) < max_len and len(pair[1].split()) < max_len]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9ErPqK6NUdN",
        "colab_type": "code",
        "outputId": "787b104c-71de-4b4f-b387-d805edfac84f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print('before filteration of pairs , there are {} pairs/conversations \\n'.format(len(pairs)))\n",
        "pairs = filterPair(pairs)\n",
        "print('after filteration of pairs , there are {} pairs/conversations'.format(len(pairs)))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "before filteration of pairs , there are 221282 pairs/conversations \n",
            "\n",
            "after filteration of pairs , there are 64271 pairs/conversations\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZkNH39aPRsj",
        "colab_type": "text"
      },
      "source": [
        "# Let's remove rarely use words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhD1gaNjPZcX",
        "colab_type": "code",
        "outputId": "03957191-d62b-46b2-de8f-bd7173759213",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "  #loop throw the filtered pairs and pass through the vocabulary class which we created \n",
        "  voc = vocabulary('cornell movie-dialogs corpus')\n",
        "  for pair in pairs:\n",
        "    voc.addSentence(pair[0]) #question\n",
        "    voc.addSentence(pair[1]) #reply\n",
        "  print(\"number of words : \", voc.num_words)\n",
        "\n",
        "  #visualize some of the pairs\n",
        "\n",
        "  for pair in pairs[:10]:\n",
        "    print(pair)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of words :  18007\n",
            "['there .', 'where ?']\n",
            "['you have my word . as a gentleman', 'you re sweet .']\n",
            "['hi .', 'looks like things worked out tonight huh ?']\n",
            "['you know chastity ?', 'i believe we share an art instructor']\n",
            "['have fun tonight ?', 'tons']\n",
            "['well no . . .', 'then that s all you had to say .']\n",
            "['then that s all you had to say .', 'but']\n",
            "['but', 'you always been this selfish ?']\n",
            "['do you listen to this crap ?', 'what crap ?']\n",
            "['what good stuff ?', 'the real you .']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeBPsorpQt6t",
        "colab_type": "code",
        "outputId": "55442d9c-311c-4889-c774-61cc3534d787",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\"\"\"\n",
        "loop through pairs and take only those pair which contain numbers which occures more than thershold \n",
        "if any of the word occurence is less than thershold than whole question and reply pair will remove\n",
        "\"\"\"\n",
        "\n",
        "min_count = 3 #threshold\n",
        "#voc : object of vocabulary class; pairs : output from above cell; min_count : threshold\n",
        "\n",
        "def trimRareWords(voc, pairs, min_count):\n",
        "  voc.trim(min_count) # trim is a method from vocabulary class gives word2index, word2count and index2words dictionaries\n",
        "  keep_pairs = []\n",
        "  for pair in pairs:\n",
        "    input_sentence = pair[0]\n",
        "    output_sentence = pair[1]\n",
        "    keep_input = True  # default true if not present in word2index dictionary than set to false\n",
        "    keep_output = True  # default true if not present in word2index dictionary than set to false\n",
        "    #check if any of the word in pair[0] and pair[1] (i.e question and reply) is not present in word2index dictionary than remove whole pair of conversation \n",
        "    #check for pair[0] (question)\n",
        "    for word in input_sentence.split(' '):\n",
        "      if word not in voc.word2index: \n",
        "        keep_input = False\n",
        "        break\n",
        "    \n",
        "    #check for pair[1] (reply)\n",
        "    for word in output_sentence.split(' '):\n",
        "      if word not in voc.word2index: \n",
        "        keep_output = False\n",
        "        break\n",
        "\n",
        "    #only keep if keep_input & keep_output both are true \n",
        "    if keep_input and keep_output:\n",
        "      keep_pairs.append(pair)\n",
        "  print(\" trimmed from {} pairs to {}, {:.4f} of total\".format(len(pairs), len(keep_pairs),  len(keep_pairs)/ len(pairs)))\n",
        "  return keep_pairs\n",
        "\n",
        "pairs = trimRareWords(voc, pairs, min_count)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "keep words 7822 / 18004 = 0.4345\n",
            " trimmed from 64271 pairs to 53125, 0.8266 of total\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "te3YM2oulgyU",
        "colab_type": "text"
      },
      "source": [
        "# preapering data for model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0yXNYjRXQoV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "get index of each word in sentence with end of sentence \n",
        "e.g index of 'hi' = 0, 'hello'=1, EOS(end f sentence) =2\n",
        "input :'hi hello'; output:[0,1,2]\n",
        "\"\"\"\n",
        "\n",
        "def indexesFromSentence(voc,sentence):\n",
        "  #word2index is a dictionary which contai word as key and index as value\n",
        "  return [voc.word2index[word] for word in sentence.split(' ')] + [EOS_token]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zkQu2W2omb-",
        "colab_type": "code",
        "outputId": "b291e227-7b28-45f0-ffa9-512fecd9af40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print('sentence : ',pairs[1][0])\n",
        "print('index of each word in sentence :', indexesFromSentence(voc,pairs[1][0]))\n",
        "print('number of words in sentence {} + 1(EOS_token) = {}'.format(len(pairs[1][0].split()), len(pairs[1][0].split())+1) )"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentence :  you have my word . as a gentleman\n",
            "index of each word in sentence : [7, 8, 9, 10, 4, 11, 12, 13, 2]\n",
            "number of words in sentence 8 + 1(EOS_token) = 9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2a2bCFyp0Fs",
        "colab_type": "code",
        "outputId": "1a9c3a07-43cb-4475-ff19-12ad5f7a460e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "#lets try with some pairs \n",
        "questions = []\n",
        "replys = []\n",
        "for pair in pairs[:10]:\n",
        "  questions.append(pair[0])\n",
        "  replys.append(pair[1])\n",
        "#let only print questions\n",
        "print(questions)\n",
        "print(len(questions))\n",
        "indexes = [indexesFromSentence(voc, sentence) for sentence in questions]\n",
        "print(indexes)\n",
        "print('each list contain 2 at end which shows end of sentence')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['there .', 'you have my word . as a gentleman', 'hi .', 'have fun tonight ?', 'well no . . .', 'then that s all you had to say .', 'but', 'do you listen to this crap ?', 'what good stuff ?', 'wow']\n",
            "10\n",
            "[[3, 4, 2], [7, 8, 9, 10, 4, 11, 12, 13, 2], [16, 4, 2], [8, 31, 22, 6, 2], [33, 34, 4, 4, 4, 2], [35, 36, 37, 38, 7, 39, 40, 41, 4, 2], [42, 2], [47, 7, 48, 40, 45, 49, 6, 2], [50, 51, 52, 6, 2], [58, 2]]\n",
            "each list contain 2 at end which shows end of sentence\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCZcIh36zack",
        "colab_type": "code",
        "outputId": "1210ca0a-c96c-44b6-91b5-2adbb7fcf47b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "\"\"\"\n",
        " *there is difference between 'zip' & 'zip_longest'\n",
        " *'zip_longest' is a method of itertools class\n",
        " *we prefere 'zip_longest' insted of 'zip' because for 'zip' need to have all list/tuples same number of elements \n",
        "  else it willremove extra elements but in 'zip_longest' it will give 'None' value \n",
        "\"\"\"\n",
        "a = [1,2,3,4]\n",
        "b = [4,5,6]\n",
        "print(list(itertools.zip_longest(a,b)))\n",
        " \n",
        "# if we want '0' insted of 'None'\n",
        "print(list(itertools.zip_longest(a,b,fillvalue=0))) \n",
        "#we can give any value as fillvalue\n",
        "print(list(itertools.zip_longest(a,b,fillvalue='d'))) \n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(1, 4), (2, 5), (3, 6), (4, None)]\n",
            "[(1, 4), (2, 5), (3, 6), (4, 0)]\n",
            "[(1, 4), (2, 5), (3, 6), (4, 'd')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8B6OROqYsW1z",
        "colab_type": "code",
        "outputId": "86d6850c-d14e-4072-a4ab-0dde75e6a0d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#let's start with zeropadding i.e give 0 value if value is not present\n",
        "\"\"\"\n",
        "as we know max length of any nested list will be 10\n",
        "we declare during 'filtering the text' in filterPair() method\n",
        "so if length of any nested list is less than 10 than it will pad with 0 to make length eqqal to 10\n",
        "\"\"\"\n",
        "nested_list = [[3, 4, 2], \n",
        "              [7, 8, 9, 10, 4, 11, 12, 13, 2], \n",
        "              [16, 4, 2], \n",
        "              [8, 31, 22, 6, 2], \n",
        "              [33, 34, 4, 4, 4, 2], \n",
        "              [35, 36, 37, 38, 7, 39, 40, 41, 4, 2], \n",
        "              [42, 2], [47, 7, 48, 40, 45, 49, 6, 2], \n",
        "              [50, 51, 52, 6, 2],\n",
        "              [58, 2]]\n",
        "\n",
        "# we know max length is 10 but still let check for it\n",
        "leng = [len(ind) for ind in nested_list]\n",
        "print(\"length of each list inside 'nested_list' : {}\\n \".format(leng))\n",
        "print('maximum length is', max(leng))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "length of each list inside 'nested_list' : [3, 9, 3, 5, 6, 10, 2, 8, 5, 2]\n",
            " \n",
            "maximum length is 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5B2gMEHY9MHl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def zerPadding(l,fillvalue = 0):\n",
        "  return list(itertools.zip_longest(*l, fillvalue= fillvalue))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yt0M0Ff9dIt",
        "colab_type": "code",
        "outputId": "f8c9d185-db53-4c88-d961-7a7f2fd991da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#let test zeroPadding() function on 'nested_list'\n",
        "test_result = zerPadding(nested_list)\n",
        "print(test_result)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(3, 7, 16, 8, 33, 35, 42, 47, 50, 58), (4, 8, 4, 31, 34, 36, 2, 7, 51, 2), (2, 9, 2, 22, 4, 37, 0, 48, 52, 0), (0, 10, 0, 6, 4, 38, 0, 40, 6, 0), (0, 4, 0, 2, 4, 7, 0, 45, 2, 0), (0, 11, 0, 0, 2, 39, 0, 49, 0, 0), (0, 12, 0, 0, 0, 40, 0, 6, 0, 0), (0, 13, 0, 0, 0, 41, 0, 2, 0, 0), (0, 2, 0, 0, 0, 4, 0, 0, 0, 0), (0, 0, 0, 0, 0, 2, 0, 0, 0, 0)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rp_OlsSD_Ld-",
        "colab_type": "text"
      },
      "source": [
        "test_result =  \n",
        "\n",
        "[(3, 7, 16, 8, 33, 35, 42, 47, 50, 58),                                              \n",
        "(4, 8, 4, 31, 34, 36, 2, 7, 51, 2),                             \n",
        "(2, 9, 2, 22, 4, 37, 0, 48, 52, 0),                                \n",
        "(0, 10, 0, 6, 4, 38, 0, 40, 6, 0),                                  \n",
        "(0, 4, 0, 2, 4, 7, 0, 45, 2, 0),                                    \n",
        "(0, 11, 0, 0, 2, 39, 0, 49, 0, 0),                                     \n",
        "(0, 12, 0, 0, 0, 40, 0, 6, 0, 0),                                 \n",
        "(0, 13, 0, 0, 0, 41, 0, 2, 0, 0),                                          \n",
        "(0, 2, 0, 0, 0, 4, 0, 0, 0, 0),                                         \n",
        "(0, 0, 0, 0, 0, 2, 0, 0, 0, 0)]                                                     \n",
        "  \n",
        "***\n",
        "[1]. where 1st tuple contain 1st elements of each list inside 'nested_list', 2nd tuple contain 2nd elements of each list inside 'nested_list', 3rd tuple contain 3rd elements of each list inside 'nested_list', and so on .... \n",
        "***\n",
        "[2].  and if element not prsesnt in list it will put 0 in tuple.\n",
        "***\n",
        "[3]. now max length is number of rows as we interchange rows and columns.\n",
        "***\n",
        "[4]. each element in list is nothing but token/index number of each word\n",
        "***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJJukhr2DQmu",
        "colab_type": "text"
      },
      "source": [
        "#Prepare data for our Model(input data)  :\n",
        "\n",
        "#BInary Matrix Formation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StYtXrjWDein",
        "colab_type": "text"
      },
      "source": [
        "les't create binary matrix "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nltLYDvbDlDQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def binaryMatrix(l, value = 0):\n",
        "  inp_matrix = []\n",
        "  for i,lis in enumerate(l):\n",
        "    inp_matrix.append([])\n",
        "    for elem in lis:\n",
        "      if elem == 0:\n",
        "        inp_matrix[i].append(0)\n",
        "      else:\n",
        "        inp_matrix[i].append(1)\n",
        "  return inp_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7jRx6WnFHh-",
        "colab_type": "code",
        "outputId": "e38baca8-2d3b-406d-b07e-aebc46e1a816",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "#test above function with 'test_result' matrix\n",
        "result = binaryMatrix(test_result)\n",
        "result"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              " [1, 1, 1, 1, 1, 1, 0, 1, 1, 0],\n",
              " [0, 1, 0, 1, 1, 1, 0, 1, 1, 0],\n",
              " [0, 1, 0, 1, 1, 1, 0, 1, 1, 0],\n",
              " [0, 1, 0, 0, 1, 1, 0, 1, 0, 0],\n",
              " [0, 1, 0, 0, 0, 1, 0, 1, 0, 0],\n",
              " [0, 1, 0, 0, 0, 1, 0, 1, 0, 0],\n",
              " [0, 1, 0, 0, 0, 1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaOp8fvMF3pK",
        "colab_type": "text"
      },
      "source": [
        "test_result =  \n",
        "\n",
        "[(3, 7, 16, 8, 33, 35, 42, 47, 50, 58),                                              \n",
        "(4, 8, 4, 31, 34, 36, 2, 7, 51, 2),                             \n",
        "(2, 9, 2, 22, 4, 37, 0, 48, 52, 0),                                \n",
        "(0, 10, 0, 6, 4, 38, 0, 40, 6, 0),                                  \n",
        "(0, 4, 0, 2, 4, 7, 0, 45, 2, 0),                                    \n",
        "(0, 11, 0, 0, 2, 39, 0, 49, 0, 0),                                     \n",
        "(0, 12, 0, 0, 0, 40, 0, 6, 0, 0),                                 \n",
        "(0, 13, 0, 0, 0, 41, 0, 2, 0, 0),                                          \n",
        "(0, 2, 0, 0, 0, 4, 0, 0, 0, 0),                                         \n",
        "(0, 0, 0, 0, 0, 2, 0, 0, 0, 0)]     \n",
        "\n",
        "******\n",
        "it shows that each tuple converted to list & if element is 'non zero' than put '1' and if element is 'zero' than put '0'\n",
        "***\n",
        "\n",
        "resullt =                                                                     \n",
        "[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],                                                      \n",
        " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],                                                         \n",
        " [1, 1, 1, 1, 1, 1, 0, 1, 1, 0],                                                            \n",
        " [0, 1, 0, 1, 1, 1, 0, 1, 1, 0],                                      \n",
        " [0, 1, 0, 1, 1, 1, 0, 1, 1, 0],                                                           \n",
        " [0, 1, 0, 0, 1, 1, 0, 1, 0, 0],                                                        \n",
        " [0, 1, 0, 0, 0, 1, 0, 1, 0, 0],                                                         \n",
        " [0, 1, 0, 0, 0, 1, 0, 1, 0, 0],                                                            \n",
        " [0, 1, 0, 0, 0, 1, 0, 0, 0, 0],                                                         \n",
        " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]]                                                                                                                                           "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLI70pqGmsT6",
        "colab_type": "text"
      },
      "source": [
        "# Input data for model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IO-uGXOF948",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "1.this function takes the list of all 'questions' in the conversation as input and returs padded input sequesce \n",
        "than we convert that padded input senquence into 'torch.tensor' format for model and also take the length of each\n",
        "batch inside tensor\n",
        "\"\"\"\n",
        "#l = list of questions ; voc = vocabulary class obet\n",
        "\n",
        "def inputVar(l,voc):\n",
        "  #indexesFromSentence() this fuction gives us the list of indexes for each sentence/question\n",
        "  indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
        "  #take the length of each list of indexes & conver list into torch.tensor()\n",
        "  lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
        "  # padding operation using zeroPadding() function\n",
        "  padList = zerPadding(indexes_batch)\n",
        "  #convert padList into torch.tensor() with each element is of long type\n",
        "  padVar = torch.LongTensor(padList)\n",
        "  #return padded torch tensor & length of each list inside tensor\n",
        "  return padVar, lengths"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHF60K7VpqXz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "this function contain some operation similar as above function & some extra operations\n",
        "\n",
        "for this fuction we take list of all 'reply' as input, convert each word of reply/sentence into list of indexes(i.e each index number for each words),\n",
        "take the maximum length among all the list of indexes, do padding operation \n",
        "\n",
        "now use padding operation as input and perform 2 operations,\n",
        "1. output of padding operation -> perform binary operation to get 1s and 0s -> convert into torch byte tensor\n",
        "2. output of padding operation -> convert each integer into long type\n",
        "\n",
        "3 OUTPUT of function:\n",
        "maximum length, tensor with all long type, byte tensors\n",
        "\"\"\"\n",
        "#l = list of questions ; voc = vocabulary class obet\n",
        "def outputVar(l, voc):\n",
        "  #indexesFromSentence() this fuction gives us the list of indexes for each sentence/question\n",
        "  indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
        "  #take the maximum length among the list of length\n",
        "  max_length = max([len(indexes) for indexes in indexes_batch])\n",
        "  # padding operation using zeroPadding() function\n",
        "  padList = zerPadding(indexes_batch)\n",
        "  #convert padList into list of 1s and 0s\n",
        "  mask = binaryMatrix(padList)\n",
        "  #convert mask list into byte tensor\n",
        "  mask = torch.ByteTensor(mask)\n",
        "  #convert each elemnt of padList into Long type\n",
        "  padVar = torch.LongTensor(padList)\n",
        "  #3 output of function is 1.tensor with all long type, 2.byte tensors, 3.maximum length\n",
        "  return padVar, mask, max_length\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvfTqn0KtrP3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#voc = object of vocabulary class; pair_batch = it is nested list and each lit contain 2 elements question,answer  \n",
        "def batch2TrainData(voc, pair_batch):\n",
        "  #each list inside pair_batch 1st-elment is question & 2nd is answer,now sort the pair_batch list by length of question\n",
        "  pair_batch.sort(key = lambda x: len(x[0].split(' ')), reverse = True)\n",
        "  input_batch,output_batch = [],[]\n",
        "  for pair in pair_batch:\n",
        "    input_batch.append(pair[0])\n",
        "    output_batch.append(pair[1])\n",
        "  #use inputVar() & outputVar() function's which are created above\n",
        "  inp, lengths = inputVar(input_batch, voc)\n",
        "  output, mask, max_length = outputVar(output_batch, voc)\n",
        "  return inp, lengths, output, mask, max_length\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oObVVV-NzOLs",
        "colab_type": "code",
        "outputId": "d410b41f-593e-43ce-cc5b-71d74aa8092c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        }
      },
      "source": [
        "\"\"\"\n",
        "pairs is a nested list, in which each list contain 2 elements 1st is question and 2nd is answer\n",
        "\"\"\"\n",
        "#take 1st 5 list inside pairs-list\n",
        "lis = []\n",
        "for i in range(5):\n",
        "  lis.append(pairs[i])\n",
        "\n",
        "#let test batch2TrainData() function \n",
        "inp, lengths, output, mask, max_length = batch2TrainData(voc, lis)\n",
        "print('input variables :')\n",
        "print(inp)\n",
        "print('\\n list of lengths of each sentence : ', lengths)\n",
        "print('\\n target variables :')\n",
        "print(output)\n",
        "print('\\n byte tensor :')\n",
        "print(mask)\n",
        "print('\\n maximum length among output tensors :', max_length)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input variables :\n",
            "tensor([[ 7, 33,  8,  3, 16],\n",
            "        [ 8, 34, 31,  4,  4],\n",
            "        [ 9,  4, 22,  2,  2],\n",
            "        [10,  4,  6,  0,  0],\n",
            "        [ 4,  4,  2,  0,  0],\n",
            "        [11,  2,  0,  0,  0],\n",
            "        [12,  0,  0,  0,  0],\n",
            "        [13,  0,  0,  0,  0],\n",
            "        [ 2,  0,  0,  0,  0]])\n",
            "\n",
            " list of lengths of each sentence :  tensor([9, 6, 5, 3, 3])\n",
            "\n",
            " target variables :\n",
            "tensor([[ 7, 35, 32,  5, 17],\n",
            "        [14, 36,  2,  6, 18],\n",
            "        [15, 37,  0,  2, 19],\n",
            "        [ 4, 38,  0,  0, 20],\n",
            "        [ 2,  7,  0,  0, 21],\n",
            "        [ 0, 39,  0,  0, 22],\n",
            "        [ 0, 40,  0,  0, 23],\n",
            "        [ 0, 41,  0,  0,  6],\n",
            "        [ 0,  4,  0,  0,  2],\n",
            "        [ 0,  2,  0,  0,  0]])\n",
            "\n",
            " byte tensor :\n",
            "tensor([[1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1],\n",
            "        [1, 1, 0, 1, 1],\n",
            "        [1, 1, 0, 0, 1],\n",
            "        [1, 1, 0, 0, 1],\n",
            "        [0, 1, 0, 0, 1],\n",
            "        [0, 1, 0, 0, 1],\n",
            "        [0, 1, 0, 0, 1],\n",
            "        [0, 1, 0, 0, 1],\n",
            "        [0, 1, 0, 0, 0]], dtype=torch.uint8)\n",
            "\n",
            " maximum length among output tensors : 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtwUB2vm6kCH",
        "colab_type": "text"
      },
      "source": [
        "# Start with Model\n",
        "\n",
        "we are using RNN model (GRU)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfMnsnV365BK",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://miro.medium.com/max/3032/1*yBXV9o5q7L_CvY7quJt3WQ.png\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6Pck92x7foq",
        "colab_type": "text"
      },
      "source": [
        "#SEquence to Sequence GRU Model\n",
        "\n",
        "It contain 'Encoder' & 'Decoder'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXwRlkzC7sJH",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://cntk.ai/jup/s2s.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y85iZHFR8j14",
        "colab_type": "text"
      },
      "source": [
        "We are using \"Bidirectional-GRU\", means there is 2 independent RNN\n",
        "1. fed the input sequence in normal sequential order\n",
        "2. fed the input squence in reverse order"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpJ1X8uv9Zlo",
        "colab_type": "text"
      },
      "source": [
        "# define Encoder Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7OFMCg19efh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#inherit from 'nn' class  'Module' method from pytorch package \n",
        "class EncoderRNN(nn.Module):\n",
        "  #create constructor\n",
        "  \"\"\"\n",
        "  hidden_size = number of nuerons in hidden lay,\n",
        "  embedding = searching/learning for words that have same meaning as given input word, \n",
        "  n_layers = number of hidden layers,\n",
        "   dropout = % of drop neurons from hidden layer\n",
        "  \"\"\"\n",
        "  def __init__(self, hidden_size, embedding, n_layers =1, dropout =0):\n",
        "    #inherit from super class\n",
        "    super(EncoderRNN, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.embedding = embedding\n",
        "    self.n_layers = n_layers\n",
        "    #set 'input_size' & 'hidden_size' parameters equal to 'hiden_size'\n",
        "    #we are using embedding (look in the pytorch documentaion for more details)\n",
        "    #initialize GRU: nn.GRU(input_size,hidden_size,n_layers, dropout, bidirectional)\n",
        "    self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers ==1 else dropout), bidirectional = True)\n",
        "\n",
        "  #forward propagation\n",
        "  \"\"\"\n",
        "  input_seq = bath of input sentence, each of shape=(max_length, batch_size),\n",
        "  input_lengths = list of each sentence length,\n",
        "  hidden = hidden state between each channel, shape =(n_layers * num_directions, batch_size, hidden_size)  \n",
        "  \"\"\"\n",
        "  def forward(self, input_seq, input_lengths, hidden = None):\n",
        "    embedded = self.embedding(input_seq)\n",
        "    #we can either use pack padded or normal (in this RNN we are using pack padded inputs)\n",
        "    packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
        "    #forward pass through GRU\n",
        "    output, hidden = self.gru(packed,hidden)\n",
        "    #unpack padding\n",
        "    outputs,_ = torch.nn.utils.rnn.pad_packed_sequence(output)\n",
        "    #take the sum of both GRU (Bidirectional GRU)\n",
        "    outputs = outputs[:, :, :self.hidden_size] + outputs[:, :, self.hidden_size:]\n",
        "    # it will return output and final hidden state (more details on documentation of pytorch)\n",
        "    return outputs, hidden\n",
        "\n",
        "    \"\"\"\n",
        "    outputs: the output feature from the last layer of the GRU, for each timestep(sum of bidirectional outputs)\n",
        "    outputs shape = (max_length, batch_size, hidden_size)\n",
        "    \n",
        "    hidden: hidden state from the last timestep only, of shape=(n_layers * num_directions, batch_size, hidden_size)\n",
        "    \"\"\"\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APbClmHDbbMy",
        "colab_type": "text"
      },
      "source": [
        "# Define the Decoder with Attention mechanism"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cx2Q0R8Ku1X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Attention Class\n",
        "\n",
        "#inherti from torch.nn.Module\n",
        "class Attn(torch.nn.Module):\n",
        "  def __init__(self, method, hidden_size):\n",
        "    super(Attn, self).__init__()\n",
        "    self.method = method\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "  #elemnet wise multiplication of encoder_output & current GRU decoder state\n",
        "  def dot_product(self, hidden, encode_output): \n",
        "    return torch.sum(hidden * encoder_output, dim = 2)\n",
        "\n",
        "  \n",
        "  \"\"\"\n",
        "  encoder_output: of shape=(max_length, batch_size, hidden_size)\n",
        "  hidden: of shape=(1, batch_size, hidden_size) ; 1 becuse each GRU have only one element\n",
        "  \n",
        "  after taking dot product of hidden & encoder_output we will get:\n",
        "  (max_length, batch_size, hidden_size) * (1, batch_size, hidden_size) = (max_length, batch_size, hidden_size)\n",
        "    \n",
        "  dim=2 in dot_product() function means addition of last 2 dimension (i.e  batch_size + hidden_size)\n",
        "  which is of size batch_size \n",
        "  so the output of dot_product() function is (max_length, batch_size)\n",
        "  \"\"\"\n",
        "  def forward(self, hidden, encoder_outputs):\n",
        "    attn_engergies = self.dot_product(hidden, encoder_output) #(max_length, batch_size)\n",
        "    #transpose max_length & batch_size dimensions\n",
        "    attn_engergies = attn_engergies.t() #(batch_size, max_length)\n",
        "    #now perform softmax normalization(with added dimension)\n",
        "    return f.softmax(max_length, dim =1).unsqueeze(1) #(batch_size, 1, max_length)\n",
        "\n",
        "    #f is a function which is imported "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sb81R7uXicT9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#decoder class\n",
        "\n",
        "#inherit from nn.Module\n",
        "class LuongAttnDecoderRNN(nn.Module):\n",
        "  #create constructor\n",
        "  \"\"\"\n",
        "  attn_model = model that we are providing in 'Attension Mechanism' \n",
        "  embedding = searching/learning for words that have same meaning as given input word, \n",
        "  hidden_size = number of nuerons in hidden lay,\n",
        "  output_size = output matrix size, of shape = (max_length, batch_size, hidden_size),\n",
        "  n_layers = number of hidden layers,\n",
        "   dropout = % of drop neurons from hidden layer\n",
        "  \"\"\"\n",
        "  def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers =1, dropout =0.1):\n",
        "    super(LuongAttnDecoderRNN, self).__init__()\n",
        "    self.attn_model = attn_model\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "    self.n_layers = n_layers\n",
        "    self.dropout = dropout\n",
        "\n",
        "    #define layers\n",
        "    self.embedding = embedding\n",
        "    self.embendding_dropout = nn.Dropout()  #also we are using dropout for embendding\n",
        "    #bidirection is false\n",
        "    self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers ==1 else dropout))\n",
        "    #after concatinating attension model output & GRU output we get size of (bach_size, hidden_size *2)\n",
        "    #for perfoming 'tanh operation we converting this into (hidden_size * 2, hidden)\n",
        "    self.concat = nn.Linear(hidden_size * 2, hidden)\n",
        "    #befor putting into softmax we agin convert it into (hidden_size, output_size)\n",
        "    self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    self.attm = Attn(attn_model, hidden_size)\n",
        "\n",
        "  #forward from one GRU to another at 'Decoder'\n",
        "  \"\"\"\n",
        "  input_step = one time step of input sequence for predincting one word(1st GRE), of shape=(1, batch_size)\n",
        "  last_hidden = hidden state from last GRU, of shape = (n_layers * num_directions, batch_size, hidden_size)\n",
        "  encoder_output = encoder model's output, of shape = (ax_length, batch_size, hidden_size)\n",
        "  \"\"\"\n",
        "  def forward(self, input_step, last_hidden, encoder_output):\n",
        "    # 1.embedding current input words (batch)\n",
        "    embedded = self.embendding(input_step)\n",
        "    # 2.perform dropout on embedded output\n",
        "    embedded = self.embendding_dropout(embedded)\n",
        "    # 3.forward pass through unidirectional GRU\n",
        "    rnn_output, hidden = self.gru(embedded, last_hidden)\n",
        "    # 4.calculating the attention weights from the current GRU mmodel output\n",
        "    attn_weights = self.attn(rnn_output, encoder_output)\n",
        "    # 5. context vector/weighted sum = attention weights * encoder outputs\n",
        "    #bmm = batch multiplication mechanisum\n",
        "    #(batch_size,1,max_length) bmm (batch_size, max_length, hidden) = (batch_size, 1 , hidden)\n",
        "    #matrix multiplication, (1, max_length) matrix multiplication (max_length, hidden) = (1,hidden)\n",
        "    #so the context shape= (batch_size, 1, hidden)\n",
        "    context = attn_weights.bmm(encoder_output.transpose(0,1)) \n",
        "    # 6. we have GRU output 'rnn_output' shape=(1, batch_size, hidden_size) & context shape= (batch_size, 1, hidden)\n",
        "    #    remove 1 by using squeeze\n",
        "    rnn_output = rnn_output.squeez(0) # 0 is position in shape\n",
        "    context = context.squeez(1) # 1 is position in shape\n",
        "    # 7. concate GRU output shape = (batch_size, hidden_size) & context vector = (batch_size, hidden_size)\n",
        "    # 1 is dimention number i.e column\n",
        "    #concatination result shape = (batch_size, hidden_size * 2)\n",
        "    concat_input = torch.cat((rnn_output,context), 1) \n",
        "    # 8. pass concat_input through 'Linear layer' to for shape = (batch_size, hidden_size)\n",
        "    #now this newly created shape is passes through 'tanh' activation function\n",
        "    #(batch_size, hidden_size) -> tanh -> (batch_size, voc_size)\n",
        "    concat_output = torch.tanh(self.concat(concat_input)) #self.concat represent Linear layer as we declear in constructor\n",
        "    # 9. pass concat_output through 'Linear layer' for output prediction\n",
        "    output = self.out(concat_output) #self.out represent 2nd Linear layer as we declear in constructor\n",
        "    # 10. pass this outputs through softmax to get ranging between 0-1 for each output\n",
        "    output = f.softmax(output, dim =1) #dim =1 (1 column)\n",
        "    #this function returns output & final hidden state which passes for next GRU as input for predicting next word\n",
        "    return output, hidden\n",
        "    #output shape = (batch_size, voc_size)\n",
        "    #hidden = (n_layers * n_directions, batch_size, hidden_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ojdAGIIxs0y",
        "colab_type": "text"
      },
      "source": [
        "# Loss Function\n",
        "*                                                        we are using 'Teacher Forcing' for o.5 time and remaning 0.5 'No Teacher Forcing' at Training\n",
        "* 'No Teacher Forcing' at Testing                     "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0UW26_Wgj5H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "*decoder_output is getting from LuongAttnDecoderRNN lass\n",
        "*mask and target we are getting from batch2TrainData() function which we created\n",
        "\n",
        "mask is a matrix of 1s & 0s, we ignore 0s and calculate 'loss' only for 1s\n",
        "\"\"\"\n",
        "# maskKNLLLoss = mask Negartive Log LikeLihood Loss\n",
        "def maskKNLLLoss(decoder_out, target, mask):\n",
        "  nTotal = mask.sum() #this will give us total number of ones/non-zero elements in matrix\n",
        "  target = target.view(-1,1) #any number of rows that python decide and 1 column\n",
        "  #decoder shape = (batch_size, voc_size); target = (batch_size,1)\n",
        "  gathered_tensor = torch.gather(decoder_out,1,target)\n",
        "  #calculate the loss\n",
        "  crossEntrophy = -torch.log(gathered_tensor) #NLLLoss( Negartive Log LikeLihood Loss)\n",
        "  #only select/consider non-zero elements\n",
        "  loss = crossEntrophy.masked_select(mask)\n",
        "  #calculate the mean of los\n",
        "  loss = loss.mean()\n",
        "  loss = loss.to(device) #convert to currently use device (CPU/GPU)\n",
        "  #return total number of non-zero elements(nTotal), loss\n",
        "  return loss, nTotal.item()\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5G0BkyVatMnQ",
        "colab_type": "text"
      },
      "source": [
        "# Start with Iteration "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iR-oqvWYyLsM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}